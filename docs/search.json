[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ngoc Dieu Hanh Nguyen",
    "section": "",
    "text": "A little bit about me and my life."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Ngoc Dieu Hanh Nguyen",
    "section": "Education",
    "text": "Education\nUniversity of XYZ, City | Location | Sept 20XX - June 20XX"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Ngoc Dieu Hanh Nguyen",
    "section": "Experience",
    "text": "Experience\nWorkplace | Job title | April 20XX - present"
  },
  {
    "objectID": "website/projects/index.html",
    "href": "website/projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Predicting House Prices with Machine Learning\n\n\n\nPython\n\n\nMachine Learning\n\n\nData Cleaning\n\n\n\nThis project involves using machine learning algorithms to predict house prices based on various features such as location, size, and amenities. It includes data cleaning, feature engineering, and model selection.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustomer Segmentation Using Clustering Techniques\n\n\n\nR\n\n\nMachine Learning\n\n\nClustering\n\n\nStatistical Modelling\n\n\n\nThis project focuses on segmenting customers into different groups based on their purchasing behavior and demographics. It uses clustering algorithms like K-means and hierarchical clustering to identify distinct customer segments.\n\n\n\nApr 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing Global CO2 Emissions\n\n\n\nR\n\n\nData Visualization\n\n\nEnvironmental Science\n\n\n\nThis project involves creating visualizations to show trends in global CO2 emissions over time. It includes data extraction from public databases, data cleaning, and using visualization libraries to create interactive charts and graphs.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "website/blog/third-post/index.html",
    "href": "website/blog/third-post/index.html",
    "title": "Third Blog Post",
    "section": "",
    "text": "The source for any page in your website could also be a Jupyter Notebook. This one is third-post/index.ipynb.\nHere’s an example I borrowed from the Seaborn docs:\n\nimport seaborn as sns\n\nsns.set_theme(style=\"whitegrid\")\n\n# Load the diamonds dataset\ndiamonds = sns.load_dataset(\"diamonds\")\n\n# Plot the distribution of clarity ratings, conditional on carat\nsns.displot(\n    data=diamonds,\n    x=\"carat\", hue=\"cut\",\n    kind=\"kde\", height=4, aspect=1.5,\n    multiple=\"fill\", clip=(0, None),\n    palette=\"ch:rot=-.25,hue=1,light=.75\",   \n)"
  },
  {
    "objectID": "website/blog/first-post/index.html",
    "href": "website/blog/first-post/index.html",
    "title": "First Post",
    "section": "",
    "text": "Sed risus ultricies tristique nulla aliquet. Neque volutpat ac tincidunt vitae semper quis lectus nulla.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Enim sed faucibus turpis in eu mi bibendum neque. Ac orci phasellus egestas tellus rutrum tellus pellentesque eu. Velit sed ullamcorper morbi tincidunt ornare massa. Sagittis id consectetur purus ut faucibus pulvinar elementum integer. Tincidunt nunc pulvinar sapien et ligula ullamcorper malesuada proin libero. Lobortis feugiat vivamus at augue eget arcu. Aliquam ut porttitor leo a diam sollicitudin tempor id eu. Mauris a diam maecenas sed enim ut sem viverra aliquet. Enim ut tellus elementum sagittis vitae et leo duis. Molestie at elementum eu facilisis sed odio morbi quis commodo. Sapien pellentesque habitant morbi tristique senectus. Quam vulputate dignissim suspendisse in est. Nulla pellentesque dignissim enim sit amet venenatis urna cursus eget.\nVelit aliquet sagittis id consectetur purus ut faucibus pulvinar elementum. Viverra mauris in aliquam sem fringilla ut morbi tincidunt augue. Tortor at auctor urna nunc id. Sit amet consectetur adipiscing elit duis tristique sollicitudin. Aliquet nibh praesent tristique magna sit amet purus. Tristique senectus et netus et malesuada fames ac turpis. Hac habitasse platea dictumst quisque. Auctor neque vitae tempus quam pellentesque nec nam aliquam. Ultrices tincidunt arcu non sodales neque sodales ut etiam. Iaculis at erat pellentesque adipiscing. Cras tincidunt lobortis feugiat vivamus. Nisi est sit amet facilisis magna etiam. Pharetra pharetra massa massa ultricies mi quis hendrerit. Vitae sapien pellentesque habitant morbi tristique senectus. Ornare aenean euismod elementum nisi quis eleifend quam adipiscing vitae."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "website/blog/second-post/index.html",
    "href": "website/blog/second-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Quis imperdiet massa tincidunt nunc pulvinar sapien et ligula. Amet cursus sit amet dictum sit amet. Eget duis at tellus at urna condimentum. Convallis aenean et tortor at risus viverra. Tincidunt ornare massa eget egestas purus viverra accumsan. Et malesuada fames ac turpis egestas. At imperdiet dui accumsan sit amet. Ut ornare lectus sit amet est placerat. Enim nulla aliquet porttitor lacus luctus accumsan tortor posuere. Duis ultricies lacus sed turpis tincidunt id aliquet risus. Mattis enim ut tellus elementum sagittis. Dui id ornare arcu odio ut. Natoque penatibus et magnis dis. Libero justo laoreet sit amet cursus sit. Sed faucibus turpis in eu. Tempus iaculis urna id volutpat lacus laoreet.\nPhasellus vestibulum lorem sed risus. Eget felis eget nunc lobortis mattis. Sit amet aliquam id diam maecenas ultricies. Egestas maecenas pharetra convallis posuere morbi. Etiam erat velit scelerisque in dictum non consectetur a erat. Cras fermentum odio eu feugiat pretium nibh ipsum consequat. Viverra accumsan in nisl nisi scelerisque. Et netus et malesuada fames ac. Amet tellus cras adipiscing enim eu turpis egestas pretium aenean. Eget lorem dolor sed viverra ipsum nunc aliquet. Ultrices dui sapien eget mi proin sed libero enim sed. Ultricies mi eget mauris pharetra et ultrices neque. Ipsum suspendisse ultrices gravida dictum. A arcu cursus vitae congue mauris rhoncus aenean vel. Gravida arcu ac tortor dignissim convallis. Nulla posuere sollicitudin aliquam ultrices."
  },
  {
    "objectID": "website/index.html",
    "href": "website/index.html",
    "title": "Ngoc Dieu Hanh Nguyen",
    "section": "",
    "text": "A little bit about me and my life."
  },
  {
    "objectID": "website/index.html#education",
    "href": "website/index.html#education",
    "title": "Ngoc Dieu Hanh Nguyen",
    "section": "Education",
    "text": "Education\nUniversity of XYZ, City | Location | Sept 20XX - June 20XX"
  },
  {
    "objectID": "website/index.html#experience",
    "href": "website/index.html#experience",
    "title": "Ngoc Dieu Hanh Nguyen",
    "section": "Experience",
    "text": "Experience\nWorkplace | Job title | April 20XX - present"
  },
  {
    "objectID": "My_Final_Project.html",
    "href": "My_Final_Project.html",
    "title": "My Final Project",
    "section": "",
    "text": "This problem is particularly relevant to me because it provides an opportunity to explore the intersection of education and career outcomes, which is a key concern for many students, educators, and professionals alike. The factors that influence starting salaries after graduation have real-world implications, not only for students trying to plan their educational path but also for policymakers and educational institutions looking to improve the career prospects of graduates. Therefore, analyzing the relationship between academic performance and salary outcomes can show how education translates into financial success and helps both individuals and institutions make more informed choices.\nThis problem is also relevant to prospective students deciding which high school or university to attend, as well as universities and educators aiming to align their curricula with career success factors. Employers and recruiters may also find this analysis interesting, as it could offer insights into the predictive value of academic performance when hiring new graduates. In addition, this research could help policymakers and educational reformers understand if academic performance is a strong predictor of future earnings, which could inform discussions around education funding and access.\nTo understand the analysis, it is important to have some background in basic educational and career metrics. The concept of academic performance generally refers to measurable outcomes like a student’s GPA (Grade Point Average), which reflects their grades and overall academic success. A high school GPA is an indicator of a student’s performance in secondary education, while a university GPA reflects academic success at the collegiate level. The SAT score is a standardized test score widely used in the U.S. to assess a student’s readiness for college. These metrics are often seen as foundational indicators of a student’s academic ability and can influence admission to universities and their academic standing once enrolled. Also, starting salary refers to the initial compensation a graduate receives when they enter the workforce. Understanding this requires knowledge of the economic context in which new graduates find themselves, including factors like job market conditions and industry-specific salary ranges. By analyzing these variables, I would like to explore whether higher academic performance correlates with a higher starting salary and whether it can serve as a predictor of financial success post-graduation.\nOn the other hand, while academic performance is a widely accepted measure of a student’s capabilities, it may not be the sole factor influencing salary outcomes. Other elements such as internships, networking, or soft skills can also play significant roles in career success, and these factors may not always be reflected in academic scores."
  },
  {
    "objectID": "My_Final_Project.html#motivation-and-context",
    "href": "My_Final_Project.html#motivation-and-context",
    "title": "My Final Project",
    "section": "",
    "text": "This problem is particularly relevant to me because it provides an opportunity to explore the intersection of education and career outcomes, which is a key concern for many students, educators, and professionals alike. The factors that influence starting salaries after graduation have real-world implications, not only for students trying to plan their educational path but also for policymakers and educational institutions looking to improve the career prospects of graduates. Therefore, analyzing the relationship between academic performance and salary outcomes can show how education translates into financial success and helps both individuals and institutions make more informed choices.\nThis problem is also relevant to prospective students deciding which high school or university to attend, as well as universities and educators aiming to align their curricula with career success factors. Employers and recruiters may also find this analysis interesting, as it could offer insights into the predictive value of academic performance when hiring new graduates. In addition, this research could help policymakers and educational reformers understand if academic performance is a strong predictor of future earnings, which could inform discussions around education funding and access.\nTo understand the analysis, it is important to have some background in basic educational and career metrics. The concept of academic performance generally refers to measurable outcomes like a student’s GPA (Grade Point Average), which reflects their grades and overall academic success. A high school GPA is an indicator of a student’s performance in secondary education, while a university GPA reflects academic success at the collegiate level. The SAT score is a standardized test score widely used in the U.S. to assess a student’s readiness for college. These metrics are often seen as foundational indicators of a student’s academic ability and can influence admission to universities and their academic standing once enrolled. Also, starting salary refers to the initial compensation a graduate receives when they enter the workforce. Understanding this requires knowledge of the economic context in which new graduates find themselves, including factors like job market conditions and industry-specific salary ranges. By analyzing these variables, I would like to explore whether higher academic performance correlates with a higher starting salary and whether it can serve as a predictor of financial success post-graduation.\nOn the other hand, while academic performance is a widely accepted measure of a student’s capabilities, it may not be the sole factor influencing salary outcomes. Other elements such as internships, networking, or soft skills can also play significant roles in career success, and these factors may not always be reflected in academic scores."
  },
  {
    "objectID": "My_Final_Project.html#main-objective",
    "href": "My_Final_Project.html#main-objective",
    "title": "My Final Project",
    "section": "Main Objective",
    "text": "Main Objective\nThis project aims to explore how a student’s academic performance, including high school GPA, SAT score, and university GPA, influences their starting salary after graduation, with the goal of identifying key academic factors that contribute to early career financial success."
  },
  {
    "objectID": "My_Final_Project.html#packages-used-in-this-analysis",
    "href": "My_Final_Project.html#packages-used-in-this-analysis",
    "title": "My Final Project",
    "section": "Packages Used In This Analysis",
    "text": "Packages Used In This Analysis\n\nlibrary(here)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(tidymodels)\nlibrary(glmnet)\nlibrary(naniar)\nlibrary(softImpute)\n\n\n\n\nPackage\nUse\n\n\n\n\nhere\nto easily load and save data\n\n\nreadr\nto import the CSV file data\n\n\ndplyr\nto massage and summarize data\n\n\nrsample\nto split data into training and test sets\n\n\nggplot2\nto create nice-looking and informative graphs"
  },
  {
    "objectID": "My_Final_Project.html#data-description",
    "href": "My_Final_Project.html#data-description",
    "title": "My Final Project",
    "section": "Data Description",
    "text": "Data Description\nThe data I am using for this project is from the “Education & Career Success” dataset available on Kaggle, a popular platform for sharing datasets. This dataset was created and updated by Adil Shamim, who designed it to explore the relationship between academic performance and career outcomes, such as starting salary and job offers. The dataset includes 5,000 records and covers variables such as high school GPA, SAT scores, university ranking, internships completed, and starting salary, among others. Although the dataset is synthetic, it was generated using real-world trends and data from education and career success studies. The primary purpose of this dataset is to allow users to conduct exploratory data analysis, create predictive models, and gain insights into factors influencing career success based on education. Particularly, the data is not directly gathered from real students, but is instead simulated based on existing trends to provide an accessible resource for data analysis.\n\neducation_career_success &lt;- readr::read_csv(\"education_career_success.csv\")\n\n\nData Limitations\nWhile the “Education & Career Success” dataset offers a valuable resource for analyzing the impact of academic performance on career outcomes, there are several limitations when evaluating conclusions based on this data. One key limitation is that the dataset is synthetic, which means it may not fully reflect the complexities and variations found in real-world data. The data was generated based on existing trends, so it may miss nuances such as regional differences, socioeconomic factors, or the influence of specific industries on career outcomes. Additionally, there could be biases in how certain variables, like GPA or internships, are represented, which may not fully capture the diverse range of experiences students have in their academic or career paths.\nMoreover, the dataset only includes a limited set of variables, which means that important factors influencing career success, such as personal networks, family background, or access to opportunities, are not directly measured. The soft_skills_score and networking_score are subjective ratings, which could introduce bias or inconsistencies in the data collection process. Also, the dataset’s focus on a synthetic population means the conclusions drawn may not be fully generalizable to real-world populations. For example, the trends observed may not hold for different time periods, geographic locations, or industries. Finally, the dataset includes a “work-life balance” rating, which may vary significantly between companies or job types but is generalized across the entire dataset. These limitations should be carefully considered when drawing conclusions about the impact of academic performance on career success."
  },
  {
    "objectID": "My_Final_Project.html#data-wrangling-optional-section",
    "href": "My_Final_Project.html#data-wrangling-optional-section",
    "title": "My Final Project",
    "section": "Data Wrangling (Optional Section)",
    "text": "Data Wrangling (Optional Section)\nIn this analysis, I plan to build a predictive model to explore the relationship between academic performance (such as high school GPA, SAT score, and university GPA) and career outcomes (such as starting salary). Since I am looking to build a model that can generalize to new, unseen data, it is essential to split the data into a training and test set. This will allow me to train the model on one subset of the data and then evaluate its performance on a separate, unseen subset. By doing this, I can assess how well the model generalizes to new data, helping to prevent overfitting (where the model performs well on the training data but poorly on unseen data).\nI will use a standard approach for splitting the data, that is 80% of the data will be used for training, and 20% will be used for testing. This approach strikes a balance between having enough data to train the model while leaving enough data for evaluation. The data will be randomly shuffled to ensure that the split is representative of the overall dataset.\n\nset.seed(195)\nn &lt;- nrow(education_career_success)\ntrain_indices &lt;- sample(n, size = floor(0.8*n))\nECS_train &lt;- education_career_success[train_indices,]\nECS_test &lt;- education_career_success[-train_indices,]\n\n\neducation_career_success |&gt;\n  miss_var_summary()\n\n# A tibble: 20 × 3\n   variable              n_miss pct_miss\n   &lt;chr&gt;                  &lt;int&gt;    &lt;num&gt;\n 1 Student_ID                 0        0\n 2 Age                        0        0\n 3 Gender                     0        0\n 4 High_School_GPA            0        0\n 5 SAT_Score                  0        0\n 6 University_Ranking         0        0\n 7 University_GPA             0        0\n 8 Field_of_Study             0        0\n 9 Internships_Completed      0        0\n10 Projects_Completed         0        0\n11 Certifications             0        0\n12 Soft_Skills_Score          0        0\n13 Networking_Score           0        0\n14 Job_Offers                 0        0\n15 Starting_Salary            0        0\n16 Career_Satisfaction        0        0\n17 Years_to_Promotion         0        0\n18 Current_Job_Level          0        0\n19 Work_Life_Balance          0        0\n20 Entrepreneurship           0        0\n\n\n\nThe result shows that there is no missing data in the original dataset."
  },
  {
    "objectID": "My_Final_Project.html#exploratory-data-analysis",
    "href": "My_Final_Project.html#exploratory-data-analysis",
    "title": "My Final Project",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\nFirst, I will check if Starting_Salary has unusual values or not\n\n\n# Since `Starting_Salary` is described as First job salary in USD ($25,000 - $150,000)\nunusual_start_salary &lt;- ECS_train %&gt;% filter(`Starting_Salary` &lt; 25000 | `Starting_Salary` &gt; 150000)\nunusual_start_salary\n\n# A tibble: 0 × 20\n# ℹ 20 variables: Student_ID &lt;chr&gt;, Age &lt;dbl&gt;, Gender &lt;chr&gt;,\n#   High_School_GPA &lt;dbl&gt;, SAT_Score &lt;dbl&gt;, University_Ranking &lt;dbl&gt;,\n#   University_GPA &lt;dbl&gt;, Field_of_Study &lt;chr&gt;, Internships_Completed &lt;dbl&gt;,\n#   Projects_Completed &lt;dbl&gt;, Certifications &lt;dbl&gt;, Soft_Skills_Score &lt;dbl&gt;,\n#   Networking_Score &lt;dbl&gt;, Job_Offers &lt;dbl&gt;, Starting_Salary &lt;dbl&gt;,\n#   Career_Satisfaction &lt;dbl&gt;, Years_to_Promotion &lt;dbl&gt;,\n#   Current_Job_Level &lt;chr&gt;, Work_Life_Balance &lt;dbl&gt;, Entrepreneurship &lt;chr&gt;\n\n\nThe result shows that Starting_Salary has no unusual values.\n\nThen, I will explore the distribution of my response variable, Starting_Salary\n\n\nECS_train |&gt;\n  summarize(\n    num_total = n(),\n    mean = mean(Starting_Salary, na.rm = TRUE),\n    sd = sd(Starting_Salary, na.rm = TRUE),\n    min = min(Starting_Salary, na.rm = TRUE),\n    Q1 = quantile(Starting_Salary, 0.25, na.rm = TRUE),\n    median = median(Starting_Salary, na.rm = TRUE),\n    Q3 = quantile(Starting_Salary, 0.75, na.rm = TRUE),\n    max = max(Starting_Salary, na.rm = TRUE),\n    IQR = IQR(Starting_Salary, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 9\n  num_total   mean     sd   min    Q1 median    Q3    max   IQR\n      &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1      4000 50620. 14482. 25000 40300  50400 60600 101000 20300\n\n\n\nggplot(data = ECS_train,\n       mapping = aes(\n         x = Starting_Salary\n         )\n       ) + \n  geom_histogram(center = 65000, binwidth = 10000) +\n  labs(title = \"Histogram of Starting_Salary\", x = \"Starting_Salary\")\n\n\n\n\n\n\n\n\nBased on the summary and histogram, the Starting_Salary distribution shows that most graduates earn between \\(\\$40,000\\) and \\(\\$60,000\\), with a few making much higher salaries, up to \\(\\$101,000\\). Since the median is lower than the mean \\((\\$50,400 &lt; \\$50,620)\\), the salaries are slightly right-skewed, with more people earning on the lower end of the scale and fewer reaching the high salary levels, indicating that a small number of people have very high-paying jobs.\n\nSecond, I will check if High_School_GPA has unusual values or not\n\n\n# Since `High_School_GPA` is on the scale 2.0 - 4.0\nunusual_high_scho_GPA &lt;- ECS_train %&gt;% filter(`High_School_GPA` &lt; 2 | `High_School_GPA` &gt; 4)\nunusual_high_scho_GPA\n\n# A tibble: 0 × 20\n# ℹ 20 variables: Student_ID &lt;chr&gt;, Age &lt;dbl&gt;, Gender &lt;chr&gt;,\n#   High_School_GPA &lt;dbl&gt;, SAT_Score &lt;dbl&gt;, University_Ranking &lt;dbl&gt;,\n#   University_GPA &lt;dbl&gt;, Field_of_Study &lt;chr&gt;, Internships_Completed &lt;dbl&gt;,\n#   Projects_Completed &lt;dbl&gt;, Certifications &lt;dbl&gt;, Soft_Skills_Score &lt;dbl&gt;,\n#   Networking_Score &lt;dbl&gt;, Job_Offers &lt;dbl&gt;, Starting_Salary &lt;dbl&gt;,\n#   Career_Satisfaction &lt;dbl&gt;, Years_to_Promotion &lt;dbl&gt;,\n#   Current_Job_Level &lt;chr&gt;, Work_Life_Balance &lt;dbl&gt;, Entrepreneurship &lt;chr&gt;\n\n\nThe result shows that High_School_GPA has no unusual values.\n\nThen, I will explore the distribution of High_School_GPA\n\n\nECS_train |&gt;\n  summarize(\n    num_total = n(),\n    mean = mean(High_School_GPA, na.rm = TRUE),\n    sd = sd(High_School_GPA, na.rm = TRUE),\n    min = min(High_School_GPA, na.rm = TRUE),\n    Q1 = quantile(High_School_GPA, 0.25, na.rm = TRUE),\n    median = median(High_School_GPA, na.rm = TRUE),\n    Q3 = quantile(High_School_GPA, 0.75, na.rm = TRUE),\n    max = max(High_School_GPA, na.rm = TRUE),\n    IQR = IQR(High_School_GPA, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 9\n  num_total  mean    sd   min    Q1 median    Q3   max   IQR\n      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      4000  3.00 0.577     2   2.5   2.99   3.5     4     1\n\n\n\nggplot(data = ECS_train,\n       mapping = aes(\n         x = High_School_GPA\n         )\n       ) + \n  geom_histogram(center = 3, binwidth = 0.1) +\n  labs(title = \"Histogram of High_School_GPA\", x = \"High_School_GPA\")\n\n\n\n\n\n\n\n\nBased on the summary and histogram, the High_School_GPA distribution is fairly centered around a 3.0 average, with most students scoring between 2.5 and 3.5, indicating a fairly typical “B” to “B+” performance. It is roughly uniform with no extreme outliers. Since the standard deviation is 0.577, the data is fairly consistent with moderate variability.\n\nThird, I will check if SAT_Score has unusual values or not\n\n\n# Since `SAT_Score` is described as Standardized test score (900 - 1600)\nunusual_SAT_score &lt;- ECS_train %&gt;% filter(`SAT_Score` &lt; 900 | `SAT_Score` &gt; 1600)\nunusual_SAT_score\n\n# A tibble: 0 × 20\n# ℹ 20 variables: Student_ID &lt;chr&gt;, Age &lt;dbl&gt;, Gender &lt;chr&gt;,\n#   High_School_GPA &lt;dbl&gt;, SAT_Score &lt;dbl&gt;, University_Ranking &lt;dbl&gt;,\n#   University_GPA &lt;dbl&gt;, Field_of_Study &lt;chr&gt;, Internships_Completed &lt;dbl&gt;,\n#   Projects_Completed &lt;dbl&gt;, Certifications &lt;dbl&gt;, Soft_Skills_Score &lt;dbl&gt;,\n#   Networking_Score &lt;dbl&gt;, Job_Offers &lt;dbl&gt;, Starting_Salary &lt;dbl&gt;,\n#   Career_Satisfaction &lt;dbl&gt;, Years_to_Promotion &lt;dbl&gt;,\n#   Current_Job_Level &lt;chr&gt;, Work_Life_Balance &lt;dbl&gt;, Entrepreneurship &lt;chr&gt;\n\n\nThe result shows that SAT_Score has no unusual values.\n\nThen, I will explore the distribution of SAT_Score\n\n\nECS_train |&gt;\n  summarize(\n    num_total = n(),\n    mean = mean(SAT_Score, na.rm = TRUE),\n    sd = sd(SAT_Score, na.rm = TRUE),\n    min = min(SAT_Score, na.rm = TRUE),\n    Q1 = quantile(SAT_Score, 0.25, na.rm = TRUE),\n    median = median(SAT_Score, na.rm = TRUE),\n    Q3 = quantile(SAT_Score, 0.75, na.rm = TRUE),\n    max = max(SAT_Score, na.rm = TRUE),\n    IQR = IQR(SAT_Score, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 9\n  num_total  mean    sd   min    Q1 median    Q3   max   IQR\n      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      4000 1253.  204.   900  1074   1256  1432  1600   358\n\n\n\nggplot(data = ECS_train,\n       mapping = aes(\n         x = SAT_Score\n         )\n       ) + \n  geom_histogram(center = 1200, binwidth = 50) +\n  labs(title = \"Histogram of SAT_Score\", x = \"SAT_Score\")\n\n\n\n\n\n\n\n\nBased on the summary and histogram, the SAT scores are fairly evenly spread around an average score of about 1253. There is moderate variability in scores, with most students scoring between 1074 and 1432, and a few students with perfect scores of 1600. The distribution appears balanced and doesn’t have any extreme outliers.\n\nFinally, I will check if University_GPA has unusual values or not\n\n\n# Since `University_GPA` is on the scale 2.0 - 4.0\nunusual_uni_GPA &lt;- ECS_train %&gt;% filter(`University_GPA` &lt; 2 | `University_GPA` &gt; 4)\nunusual_uni_GPA\n\n# A tibble: 0 × 20\n# ℹ 20 variables: Student_ID &lt;chr&gt;, Age &lt;dbl&gt;, Gender &lt;chr&gt;,\n#   High_School_GPA &lt;dbl&gt;, SAT_Score &lt;dbl&gt;, University_Ranking &lt;dbl&gt;,\n#   University_GPA &lt;dbl&gt;, Field_of_Study &lt;chr&gt;, Internships_Completed &lt;dbl&gt;,\n#   Projects_Completed &lt;dbl&gt;, Certifications &lt;dbl&gt;, Soft_Skills_Score &lt;dbl&gt;,\n#   Networking_Score &lt;dbl&gt;, Job_Offers &lt;dbl&gt;, Starting_Salary &lt;dbl&gt;,\n#   Career_Satisfaction &lt;dbl&gt;, Years_to_Promotion &lt;dbl&gt;,\n#   Current_Job_Level &lt;chr&gt;, Work_Life_Balance &lt;dbl&gt;, Entrepreneurship &lt;chr&gt;\n\n\nThe result shows that University_GPA has no unusual values.\n\nThen, I will explore the distribution of University_GPA\n\n\nECS_train |&gt;\n  summarize(\n    num_total = n(),\n    mean = mean(University_GPA, na.rm = TRUE),\n    sd = sd(University_GPA, na.rm = TRUE),\n    min = min(University_GPA, na.rm = TRUE),\n    Q1 = quantile(University_GPA, 0.25, na.rm = TRUE),\n    median = median(University_GPA, na.rm = TRUE),\n    Q3 = quantile(University_GPA, 0.75, na.rm = TRUE),\n    max = max(University_GPA, na.rm = TRUE),\n    IQR = IQR(University_GPA, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 9\n  num_total  mean    sd   min    Q1 median    Q3   max   IQR\n      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      4000  3.02 0.574     2  2.52   3.03  3.52     4     1\n\n\n\nggplot(data = ECS_train,\n       mapping = aes(\n         x = University_GPA\n         )\n       ) + \n  geom_histogram(center = 3, binwidth = 0.05) +\n  labs(title = \"Histogram of University_GPA\", x = \"University_GPA\")\n\n\n\n\n\n\n\n\nBased on the summary and histogram, the University_GPA distribution is fairly uniform, with most students earning GPAs between 2.52 and 3.52, and an average GPA of around 3.02. The distribution is relatively consistent, with no extreme outliers, and the spread is moderate, suggesting most students perform similarly in university.\n\nInvestigate the association between the two variables.\nFirst, I will investigate the association between High_School_GPA and Starting_Salaryby creating a scatterplot to show the relationship between these two variables and see if they have a linear relationship.\n\n\nggplot(data = ECS_train,\n       mapping = aes(\n         x = High_School_GPA,\n         y = Starting_Salary\n         )\n       ) +\n  geom_point(size = 0.8) +\n  labs(title = \"High_School_GPA vs. Starting_Salary\", \n       x = \"High_School_GPA\",\n       y = \"Starting_Salary\") +\n  geom_smooth(method = \"loess\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nBased on the scatterplot, there appears to be no significant relationship between High_School_GPA and Starting_Salary. The plot does not exhibit any clear trend, and the blue regression line is nearly horizontal, suggesting that High_School_GPA does not have a meaningful effect on Starting_Salary across its range.”\nTo double check, I calculate the correlation coefficient between two variables.\n\ncor(ECS_train$Starting_Salary, ECS_train$High_School_GPA)\n\n[1] 0.002065118\n\n\nWe see that the correlation coefficient is very small (0.002), which means that there is no clear relationship between High_School_GPA and Starting_Salary.\n\nNext, I will investigate the association between SAT_Score and Starting_Salary by creating a scatterplot to show the relationship between these two variables and see if they have a linear relationship.\n\n\nggplot(data = ECS_train,\n       mapping = aes(\n         x = SAT_Score,\n         y = Starting_Salary\n         )\n       ) +\n  geom_point(size = 0.8) +\n  labs(title = \"SAT_Score vs. Starting_Salary\", \n       x = \"SAT_Score\",\n       y = \"Starting_Salary\") +\n  geom_smooth(method = \"loess\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nBased on the scatterplot, it looks like there is no relationship between SAT_Score and Starting_Salary because this plot does not show any specific trend, and the blue line seems to be horizontal across different values of SAT_Score.\nTo double check, I calculate the correlation coefficient between two variables.\n\ncor(ECS_train$Starting_Salary, ECS_train$SAT_Score)\n\n[1] 0.0009987774\n\n\nSince the correlation coefficient is close to 0 (0.001), there is no relationship between SAT_Score and Starting Salary.\n\nThen, I will investigate the association between University_GPA and Starting_Salaryby creating a scatterplot to show the relationship between these two variables and see if they have a linear relationship.\n\n\nggplot(data = ECS_train,\n       mapping = aes(\n         x = University_GPA,\n         y = Starting_Salary\n         )\n       ) +\n  geom_point(size = 0.8) +\n  labs(title = \"University_GPA vs. Starting_Salary\", \n       x = \"University_GPA\",\n       y = \"Starting_Salary\") +\n  geom_smooth(method = \"loess\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nBased on the scatterplot, it does not have any detectable trend, and the blue regression line is nearly horizontal. This indicates that University_GPA is not significantly associated with Starting_Salary.\nTo double check, I calculate the correlation coefficient between two variables.\n\ncor(ECS_train$Starting_Salary, ECS_train$University_GPA)\n\n[1] -0.00564282\n\n\nSince the correlation coefficient is close to 0 (-0.01), there is no significant relationship between University_GPA and Starting_Salary.\nThrough exploratory data analysis, I examined the relationships between starting salary and various academic factors, including high school GPA, SAT score, and university GPA. Surprisingly, the analysis revealed that none of these factors showed a meaningful relationship with starting salary. The correlation coefficients for high school GPA, SAT score, and university GPA were very close to zero, indicating weak or no linear associations with starting salary. Additionally, visual inspections of the data, such as scatterplots and regression lines, showed no discernible trends.\nThis finding suggests that academic performance, as measured by these variables, may not be strong predictors of early career financial success in this dataset. However, this does not necessarily mean that academic factors are unimportant in determining starting salary in general. Other factors not explored in this analysis, such as internships, networking, or soft skills, may play a more significant role in shaping starting salaries. Further research could investigate these other variables to provide a more comprehensive understanding of the factors influencing early career earnings."
  },
  {
    "objectID": "My_Final_Project.html#modeling",
    "href": "My_Final_Project.html#modeling",
    "title": "My Final Project",
    "section": "Modeling",
    "text": "Modeling\nI selected linear regression as the primary modeling technique for this analysis because it is a fundamental, interpretable method well-suited for examining the relationship between one or more predictor variables and a continuous response variable, such as Starting_Salary. This approach estimates the effect of each independent variable by fitting a line that minimizes the sum of squared residuals between observed and predicted values. Linear regression is particularly appropriate here because it enables us to quantify the marginal effect of each academic variable on predicted salary, provides directly interpretable coefficients (e.g., an additional SAT point corresponds to a specific increase in salary), and assumes a linear relationship that aligns—albeit weakly—with patterns observed during exploratory analysis.\nBefore fitting the model, I center and scale the numeric predictors to ensure comparability of the coefficients and avoid issues of variable scale.\n\n# Build a recipe to preprocess data\nsalary_recipe &lt;- recipe(Starting_Salary ~ High_School_GPA + SAT_Score\n                        + University_GPA,\n                        data = ECS_train) |&gt;\n  step_normalize(all_predictors())  # Standardize predictors\n\n# Define linear regression model\nlm_model &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  set_mode(\"regression\")\n\n# Create workflow\nlm_workflow &lt;- workflow() |&gt;\n  add_model(lm_model) |&gt;\n  add_recipe(salary_recipe)\n\n# Fit the model\nlm_fit &lt;- fit(lm_workflow, data = ECS_train)\n\nTo evaluate the performance of the model, I use two key metrics: Root Mean Squared Error (RMSE), which measures the average magnitude of prediction errors, and R-squared (the Coefficient of Determination), which indicates the proportion of variance in the response variable explained by the model.\n\n# Predict on the test set\ntest_predictions &lt;- predict(lm_fit, new_data = ECS_test) |&gt;\n  bind_cols(ECS_test)\n\n# Calculate performance metrics\nlm_metrics &lt;- test_predictions |&gt;\n  metrics(truth = Starting_Salary, estimate = .pred)\n\nlm_metrics\n\n# A tibble: 3 × 3\n  .metric .estimator   .estimate\n  &lt;chr&gt;   &lt;chr&gt;            &lt;dbl&gt;\n1 rmse    standard   14550.     \n2 rsq     standard       0.00174\n3 mae     standard   11909.     \n\n\nThe predictive modeling analysis reveals that the academic factors considered High_School_GPA, SAT_Score, and University_GPA do not significantly predict Starting_Salary. The model’s performance metrics, including a very low R-squared value (0.0017) and high RMSE (\\(\\${14,550.38}\\)), indicate that these variables account for very little of the variability in starting salaries.\n\n# Lasso model\nlasso_model &lt;- linear_reg(penalty = tune(), mixture = 1) |&gt; \n  set_engine(\"glmnet\") |&gt; \n  set_mode(\"regression\")\n\n# Create workflow\nlasso_workflow &lt;- workflow() |&gt;\n  add_model(lasso_model) |&gt;\n  add_recipe(salary_recipe)\n\n# 5-fold cross-validation\nset.seed(195)\ncv_folds &lt;- vfold_cv(ECS_train, v = 5)\n\n# Grid of penalty values (log scale)\npenalty_grid &lt;- grid_regular(penalty(), levels = 30)\n\n# Tune the model\nlasso_tune_results &lt;- tune_grid(\n  lasso_workflow,\n  resamples = cv_folds,\n  grid = penalty_grid,\n  metrics = metric_set(rmse, rsq, mae)\n)\n\n\n# Plot RMSE vs lambda\nlasso_tune_results |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"rmse\") |&gt;\n  ggplot(mapping = aes(x = penalty, y = mean)) + geom_point() + geom_line() +\n  scale_x_log10() +\n  labs(title = \"RMSE vs Lambda (log scale)\", x = \"Lambda (penalty)\", y =\n         \"Mean RMSE\")\n\n\n\n\n\n\n\n\n\nshow_best(lasso_tune_results, metric = \"rmse\", n = 1) # best lambda value based on the lowest RMSE\n\n# A tibble: 1 × 7\n  penalty .metric .estimator   mean     n std_err .config              \n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1       1 rmse    standard   14492.     5    140. Preprocessor1_Model30\n\n\n\nlasso_best &lt;- lasso_tune_results |&gt;\n  select_by_one_std_err(\n    metric = \"rmse\",\n    desc(penalty) # order penalty from largest (highest bias = simplest model) to smallest\n)\nlasso_best\n\n# A tibble: 1 × 2\n  penalty .config              \n    &lt;dbl&gt; &lt;chr&gt;                \n1       1 Preprocessor1_Model30\n\n\n\n# Finalize the workflow with the best penalty\nfinal_lasso_workflow &lt;- lasso_workflow |&gt;\n  finalize_workflow(parameters = lasso_best)\n\n# Fit the finalized model to the training data\nfinal_lasso_fit &lt;- final_lasso_workflow |&gt;\n  fit(data = ECS_train)\nfinal_lasso_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df %Dev Lambda\n1   0    0 81.710\n2   1    0 74.450\n3   1    0 67.840\n4   1    0 61.810\n5   1    0 56.320\n6   1    0 51.320\n7   1    0 46.760\n8   1    0 42.600\n9   1    0 38.820\n10  1    0 35.370\n11  1    0 32.230\n12  2    0 29.370\n13  2    0 26.760\n14  2    0 24.380\n15  2    0 22.210\n16  2    0 20.240\n17  2    0 18.440\n18  2    0 16.800\n19  3    0 15.310\n20  3    0 13.950\n21  3    0 12.710\n22  3    0 11.580\n23  3    0 10.550\n24  3    0  9.616\n25  3    0  8.762\n26  3    0  7.983\n27  3    0  7.274\n28  3    0  6.628\n29  3    0  6.039\n30  3    0  5.502\n31  3    0  5.014\n32  3    0  4.568\n33  3    0  4.162\n34  3    0  3.793\n35  3    0  3.456\n36  3    0  3.149\n37  3    0  2.869\n38  3    0  2.614\n39  3    0  2.382\n40  3    0  2.170\n41  3    0  1.977\n42  3    0  1.802\n43  3    0  1.642\n44  3    0  1.496\n45  3    0  1.363\n46  3    0  1.242\n\n...\nand 14 more lines.\n\n\n\n# Predict on the test set\nlasso_preds &lt;- broom::augment(final_lasso_fit, new_data = ECS_test)\n\n\n# Evaluate model performance\nlasso_metrics &lt;- lasso_preds |&gt; \n  metrics(truth = Starting_Salary, estimate = .pred)\n\nlasso_metrics\n\n# A tibble: 3 × 3\n  .metric .estimator   .estimate\n  &lt;chr&gt;   &lt;chr&gt;            &lt;dbl&gt;\n1 rmse    standard   14550.     \n2 rsq     standard       0.00173\n3 mae     standard   11909.     \n\n\nThe Lasso regression model yielded performance metrics that are nearly identical to those of the earlier linear regression model, with an RMSE of approximately \\(\\${14,550}\\), an MAE of around \\(\\${11,909}\\), and a very low R-squared value of \\(0.0017\\). These results indicate that the inclusion of regularization did not improve the model’s predictive ability, and the selected academic variables High_School_GPA, SAT_Score, and University_GPA still explain virtually none of the variation in starting salary. This reinforces the conclusion that these academic metrics alone are not strong predictors of early career financial outcomes in this dataset.\nIn this analysis, both the multiple linear regression and Lasso regression models were used to examine whether academic performance, which is measured by high school GPA, SAT score, and university GPA, could predict starting salary after graduation. The results from both models were nearly identical, with very low R-squared values (around 0.0017) and relatively high RMSE values (approximately $14,550). These outcomes indicate that academic metrics alone explain virtually none of the variation in starting salary within this dataset. Even after applying regularization through Lasso, model performance did not improve, suggesting that the predictors used lack meaningful association with the outcome variable. This highlights a key limitation of the dataset, which is both synthetic and overly simplified. It also reinforces the importance of incorporating other real-world factors such as internships, work experience, networking, or soft skills when modeling career outcomes. Without these, academic performance alone appears insufficient as a predictor of early career financial success."
  },
  {
    "objectID": "My_Final_Project.html#insights",
    "href": "My_Final_Project.html#insights",
    "title": "My Final Project",
    "section": "Insights",
    "text": "Insights\n\n# Create a data frame summarizing both models' performance\nmodel_metrics &lt;- tibble(\n  Model = c(\"Linear Regression\", \"Lasso Regression\"),\n  RMSE = c(14550.38, 14550.30),\n  MAE = c(11909.44, 11909.37),\n  R_squared = c(0.0017, 0.0017)\n)\nmodel_metrics\n\n# A tibble: 2 × 4\n  Model               RMSE    MAE R_squared\n  &lt;chr&gt;              &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n1 Linear Regression 14550. 11909.    0.0017\n2 Lasso Regression  14550. 11909.    0.0017\n\n\nAfter conducting both linear regression and Lasso regression models using High_School_GPA, SAT_Score, and University_GPA as predictors, the primary insight from this analysis is that these academic metrics have very limited predictive power for determining Starting_Salary. As illustrated in the performance comparison table above, both models produced nearly identical results, with RMSE values around \\(\\${14,550}\\) and R-squared values close to \\(0\\). This indicates that the models could not explain any meaningful variation in starting salaries using these academic factors. The finding was further supported by the near-zero correlation coefficients and flat trend lines observed in scatterplots between each academic variable and starting salary. This suggests that, at least within this dataset, early career financial outcomes are likely influenced by other variables not included in the initial models such as internships, soft skills, or professional networking, which should be explored in future analyses.\n\nLimitations and Future Work\nThere are several key limitations that affect the reliability and generalizability of the modeling results in this project. First, the models consistently performed poorly across all evaluation metrics (\\(R^2 \\approx 0.0017\\)), meaning that they failed to meaningfully predict starting salaries for almost all individuals in the dataset. This suggests that starting salaries are influenced by factors not captured in the academic variables used, and that the model is particularly weak for students across the board whether high or low achieving because it lacks relevant predictors such as internships, job field, networking, or soft skills.\nA major limitation lies in the nature of the dataset itself, which is synthetic and not based on actual student or employment records. As a result, the relationships between variables do not always reflect real-world patterns. For example, High_School_GPA and University_GPA have very similar, overly uniform distributions, which is unrealistic; in reality, University GPA tends to be more tightly clustered, and often correlates with earlier academic performance. Additionally, SAT scores are suspiciously centered and lack the expected skewness seen in real testing data. These issues likely distort any potential predictive relationships and limit the realism of the analysis.\nThe modeling methods used including linear regression and Lasso regression, which rely on certain assumptions, including linearity and the meaningfulness of the input features. Since the features used lack strong theoretical or empirical justification in this dataset, the assumptions behind these methods are weakly supported, which further undermines the model’s validity. Moreover, while regularization helps with overfitting, it cannot fix fundamentally poor data quality or irrelevant features.\nFrom an ethical standpoint, while the data is simulated and anonymized, there are still considerations about how such analysis could be interpreted. For example, using academic performance to predict salary outcomes might unintentionally reinforce meritocratic assumptions that overlook systemic inequalities in access to education or professional opportunities. In the real world, decisions based on such limited models could unfairly disadvantage individuals whose strengths lie outside standardized academic metrics.\nTo improve this analysis in the future, better data collection is essential, ideally using real, anonymized graduate outcome surveys that include richer variables: major or field of study, internship experience, job sector, geographic location, and demographic background. With more realistic and complete data, a wider range of modeling approaches such as tree-based models or mixed-effects models could be explored with more confidence in the results.\n\n\nReflection (Optional Subsection)"
  }
]